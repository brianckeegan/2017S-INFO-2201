{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 22: Reinforcement of strings with regex and NLTK\n",
    "\n",
    "We are going to discuss two other approaches to dealing with string and text data. We're going to use the [Natural Language Toolkit](http://www.nltk.org) library, but we first have to download some data corpora and libraries to use NLTK. Running this block of code *should* pop up a new window with four blue tabs: Collections, Corpora, Models, All Packages. Under Collections, Select the entry with \"book\" in the Identifier column and select download. Once the status \"Finished downloading collection 'book'.\" prints in the grey bar at the bottom, you can close this pop-up.\n",
    "\n",
    "![](http://www.nltk.org/images/nltk-downloader.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should only need to do the download step once. In the future, you can start from the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import text1, text2, text3, text4, text5, text6, text7, text8, text9\n",
    "text_list = [text1, text2, text3, text4, text5, text6, text7, text8, text9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also download text from the web and load it into a NLTK Text object. Let's get something from [Project Gutenberg's Top 100 list](https://www.gutenberg.org/browse/scores/top)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long is each body of text? We can use `len` on a `Text` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Moby Dick by Herman Melville 1851> has 260,819 words\n",
      "\n",
      "<Text: Sense and Sensibility by Jane Austen 1811> has 141,576 words\n",
      "\n",
      "<Text: The Book of Genesis> has 44,764 words\n",
      "\n",
      "<Text: Inaugural Address Corpus> has 145,735 words\n",
      "\n",
      "<Text: Chat Corpus> has 45,010 words\n",
      "\n",
      "<Text: Monty Python and the Holy Grail> has 16,967 words\n",
      "\n",
      "<Text: Wall Street Journal> has 100,676 words\n",
      "\n",
      "<Text: Personals Corpus> has 4,867 words\n",
      "\n",
      "<Text: The Man Who Was Thursday by G . K . Chesterton 1908> has 69,213 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in text_list:\n",
    "    print(\"{0} has {1:,} words\\n\".format(t,len(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique words in each text document? We can call `set` on a Text object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Moby Dick by Herman Melville 1851> has 19,317 unique words\n",
      "\n",
      "<Text: Sense and Sensibility by Jane Austen 1811> has 6,833 unique words\n",
      "\n",
      "<Text: The Book of Genesis> has 2,789 unique words\n",
      "\n",
      "<Text: Inaugural Address Corpus> has 9,754 unique words\n",
      "\n",
      "<Text: Chat Corpus> has 6,066 unique words\n",
      "\n",
      "<Text: Monty Python and the Holy Grail> has 2,166 unique words\n",
      "\n",
      "<Text: Wall Street Journal> has 12,408 unique words\n",
      "\n",
      "<Text: Personals Corpus> has 1,108 unique words\n",
      "\n",
      "<Text: The Man Who Was Thursday by G . K . Chesterton 1908> has 6,807 unique words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in text_list:\n",
    "    print(\"{0} has {1:,} unique words\\n\".format(t,len(set(t))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a function that measures the [lexical diversity](https://en.wikipedia.org/wiki/Lexical_diversity) of the text by computing the number of unique words as a percentage of the total number of words. If each word was used only once, then the richness would be 100% but if the same word was repeated the entire length of the document, then the richness would be 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Moby Dick by Herman Melville 1851> has a lexical diversity of 0.074\n",
      "\n",
      "<Text: Sense and Sensibility by Jane Austen 1811> has a lexical diversity of 0.048\n",
      "\n",
      "<Text: The Book of Genesis> has a lexical diversity of 0.062\n",
      "\n",
      "<Text: Inaugural Address Corpus> has a lexical diversity of 0.067\n",
      "\n",
      "<Text: Chat Corpus> has a lexical diversity of 0.13\n",
      "\n",
      "<Text: Monty Python and the Holy Grail> has a lexical diversity of 0.13\n",
      "\n",
      "<Text: Wall Street Journal> has a lexical diversity of 0.12\n",
      "\n",
      "<Text: Personals Corpus> has a lexical diversity of 0.23\n",
      "\n",
      "<Text: The Man Who Was Thursday by G . K . Chesterton 1908> has a lexical diversity of 0.098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text))/len(text)\n",
    "\n",
    "for t in text_list:\n",
    "    print(\"{0} has a lexical diversity of {1:.2}\\n\".format(t,lexical_diversity(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the longest words in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest word in <Text: Moby Dick by Herman Melville 1851> is: uninterpenetratingly\n",
      "\n",
      "The longest word in <Text: Sense and Sensibility by Jane Austen 1811> is: companionableness\n",
      "\n",
      "The longest word in <Text: The Book of Genesis> is: Zaphnathpaaneah\n",
      "\n",
      "The longest word in <Text: Inaugural Address Corpus> is: antiphilosophists\n",
      "\n",
      "The longest word in <Text: Chat Corpus> is: //www.wunderground.com/cgi-bin/findweather/getForecast?query=95953#FIR\n",
      "\n",
      "The longest word in <Text: Monty Python and the Holy Grail> is: understanding\n",
      "\n",
      "The longest word in <Text: Wall Street Journal> is: marketing-communications\n",
      "\n",
      "The longest word in <Text: Personals Corpus> is: DISCIPLINARIAN\n",
      "\n",
      "The longest word in <Text: The Man Who Was Thursday by G . K . Chesterton 1908> is: undenominational\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_longest_word(text):\n",
    "    longest = ''\n",
    "    for word in set(text):\n",
    "        if len(word) > len(longest):\n",
    "            longest = word\n",
    "    return longest\n",
    "\n",
    "for t in text_list:\n",
    "    print(\"The longest word in {0} is: {1}\\n\".format(t,find_longest_word(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also measure the frequency distribution of how often a word is used in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t = text1\n",
    "fdist_text1 = nltk.FreqDist(_t)\n",
    "fdist_text1.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the distribution of how often words occur in the corpus. We get an interesting pattern called the [Zipf distribution](https://en.wikipedia.org/wiki/Zipf%27s_law). There are many words that occur only once (upper left) and single words that occur thousands of times (lower right) but the pattern follows a consistent log-linear pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x124a6b898>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEaCAYAAAAG87ApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124a5f9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter_text1 = Counter(fdist_text1.values())\n",
    "\n",
    "f,ax = plt.subplots(1,1)\n",
    "ax.scatter(list(counter_text1.keys()),list(counter_text1.values()))\n",
    "ax.set_ylim((1e-1,1e5))\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(_t.name)\n",
    "ax.set_xlabel('Number of occurrences')\n",
    "ax.set_ylabel('Number of words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing text\n",
    "\n",
    "An important part of processing natural language data is normalizing this data by removing variations in the text that the computer naively thinks are different entities but humans recognize as being the same. There are several steps to this including case adjustment and stemming/lemmatization.\n",
    "\n",
    "In the case of case adjustment, it turns out several of the different \"words\" in the corpus are actually the same, but because they have different capitalizations, they're counted as different unique words. Explore how many five-letter words are the same, just with different capitalizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_letter_words = list()\n",
    "\n",
    "for w in set(text1):\n",
    "    if len(w) == 5:\n",
    "        five_letter_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2,397 five-letter words in the corpus.\n"
     ]
    }
   ],
   "source": [
    "five_letter_words = [w for w in set(text1) if len(w) == 5]\n",
    "\n",
    "print(\"There are {0:,} five-letter words in the corpus.\".format(len(five_letter_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 924 five-letter words in the corpus that are the same but have different cases.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('being', 'Being'),\n",
       " ('being', 'BEING'),\n",
       " ('LYING', 'lying'),\n",
       " ('LYING', 'Lying'),\n",
       " ('fifth', 'Fifth'),\n",
       " ('young', 'Young'),\n",
       " ('CEASE', 'cease'),\n",
       " ('OATHS', 'oaths'),\n",
       " ('speak', 'Speak'),\n",
       " ('Doesn', 'doesn')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_case_tokens = []\n",
    "\n",
    "for word1 in five_letter_words:\n",
    "    for word2 in five_letter_words:\n",
    "        if word1.lower() == word2.lower() and word1 != word2:\n",
    "            mixed_case_tokens.append((word1,word2))\n",
    "\n",
    "print(\"There are {0:,} five-letter words in the corpus that are the same but have different cases.\".format(len(mixed_case_tokens)))\n",
    "mixed_case_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19,317 unique words in text1 before lowering and 17,231 after lowering\n"
     ]
    }
   ],
   "source": [
    "text1_lowered = [i.lower() for i in text1.tokens]\n",
    "print(\"There are {0:,} unique words in text1 before lowering and {1:,} after lowering\".format(len(set(text1)),len(set(text1_lowered))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem with natural language text is plural (dogs vs. dog) and possessive (dog's vs. dog) forms, verb conjugations (walk, walks, walked, walking), and contractions (they're) are also counted as unique words even if the underlying concepts are similar. Extracting [word stems](https://en.wikipedia.org/wiki/Word_stem) means removing prefixes and affixes that result in a new token, but not a significantly new meaning.\n",
    "\n",
    "We can use a variety of [stemming](https://en.wikipedia.org/wiki/Stemming) and [lemmatization](https://en.wikipedia.org/wiki/Lemmatisation) tools in NLTK to try to recover unique words stripped of any prefixes or suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['suppli',\n",
       " 'late',\n",
       " 'consumpt',\n",
       " 'usher',\n",
       " 'grammar',\n",
       " 'school',\n",
       " 'the',\n",
       " 'pale',\n",
       " 'usher',\n",
       " 'threadbar',\n",
       " 'coat',\n",
       " 'heart',\n",
       " 'bodi',\n",
       " 'and',\n",
       " 'brain',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " 'wa',\n",
       " 'ever',\n",
       " 'dust',\n",
       " 'hi',\n",
       " 'old',\n",
       " 'lexicon',\n",
       " 'and']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "[porter.stem(t.lower()) for t in text1.tokens[10:50] if len(t) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After stemming the words in `text1`, how many unique words remain? \n",
    "\n",
    "Nearly half of the words in *Moby Dick* that were initially counted as unique were actually duplicates of other words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19,317 unique words in text1 before and 10,927 after lowering and stemming\n"
     ]
    }
   ],
   "source": [
    "text1_lowered_stemmed = set()\n",
    "\n",
    "for t in set(text1):\n",
    "    t_lower = t.lower()\n",
    "    t_stemmed = porter.stem(t_lower)\n",
    "    text1_lowered_stemmed.add(t_stemmed)\n",
    "    \n",
    "print(\"There are {0:,} unique words in text1 before and {1:,} after lowering and stemming\".format(len(set(text1)),len(set(text1_lowered_stemmed))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is a bit smarter about removing letters: it checks if the word is a plural, conjugation, etc. of another word and them \"stems\" it down to the root word only if in the dictionary. These lookups are expensive in comparision to basically slicing characters off a list like stemming, but results in better quality — but far from perfect — results. For example, \"supplied\" should have been reduced to \"supply\" and \"dusting\" and \"dust\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['supplied',\n",
       " 'late',\n",
       " 'consumptive',\n",
       " 'usher',\n",
       " 'grammar',\n",
       " 'school',\n",
       " 'the',\n",
       " 'pale',\n",
       " 'usher',\n",
       " 'threadbare',\n",
       " 'coat',\n",
       " 'heart',\n",
       " 'body',\n",
       " 'and',\n",
       " 'brain',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " 'wa',\n",
       " 'ever',\n",
       " 'dusting',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicon',\n",
       " 'and']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "[wnl.lemmatize(t.lower()) for t in text1.tokens[10:50] if len(t) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After lemmatizing the words in `text1`, how many unique words remain? Lemmatizing isn't as aggressive as stemming, but there's still a 25% reduction in the total number of unique words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19,317 unique words in text1 before and 15,168 after lowering and stemming\n"
     ]
    }
   ],
   "source": [
    "text1_lowered_lemmatized = set()\n",
    "\n",
    "for t in set(text1):\n",
    "    t_lower = t.lower()\n",
    "    t_lemmatized = wnl.lemmatize(t_lower)\n",
    "    text1_lowered_lemmatized.add(t_lemmatized)\n",
    "    \n",
    "print(\"There are {0:,} unique words in text1 before and {1:,} after lowering and stemming\".format(len(set(text1)),len(set(text1_lowered_lemmatized))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We have to pretend to be a web browser in order for it to actually give us data\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "# Congress webmasters actually have nicely parsed member data into XML for you\n",
    "senate_raw = requests.get('https://www.senate.gov/general/contact_information/senators_cfm.xml',headers=headers).text\n",
    "house_raw = requests.get('http://clerk.house.gov/xml/lists/MemberData.xml',headers=headers).text\n",
    "\n",
    "senate_soup = BeautifulSoup(senate_raw,'lxml')\n",
    "house_soup = BeautifulSoup(house_raw,'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the data that the House and the Senator provide about their respective members. The House office fields break out the building, room, ZIP code, etc. of the address while the Senate just has the full string as an address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bioguideid': 'Y000033',\n",
       " 'caucus': 'R',\n",
       " 'courtesy': 'Mr.',\n",
       " 'district': 'At Large',\n",
       " 'elected-date': 'November  8, 2016',\n",
       " 'firstname': 'Don',\n",
       " 'formal-name': 'Mr. Young of Alaska',\n",
       " 'lastname': 'Young',\n",
       " 'middlename': '',\n",
       " 'namelist': 'Young, Don',\n",
       " 'office-building': 'RHOB',\n",
       " 'office-room': '2314',\n",
       " 'office-zip': '20515',\n",
       " 'office-zip-suffix': '0200',\n",
       " 'official-name': 'Don Young',\n",
       " 'party': 'R',\n",
       " 'phone': '(202) 225-5765',\n",
       " 'prior-congress': '114',\n",
       " 'sort-name': 'YOUNG,DON',\n",
       " 'state': 'Alaska',\n",
       " 'suffix': '',\n",
       " 'sworn-date': 'January  3, 2017',\n",
       " 'townname': 'Fort Yukon'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dict = [{i.name:i.text for i in list(member.children) if i != '\\n'} for member in house_soup.find_all('member-info')]\n",
    "house_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': '455 Dirksen Senate Office Building Washington DC 20510',\n",
       " 'bioguide_id': 'A000360',\n",
       " 'class': 'Class II',\n",
       " 'email': 'http://www.alexander.senate.gov/public/index.cfm?p=Email',\n",
       " 'first_name': 'Lamar',\n",
       " 'last_name': 'Alexander',\n",
       " 'member_full': 'Alexander (R-TN)',\n",
       " 'party': 'R',\n",
       " 'phone': '(202) 224-4944',\n",
       " 'state': 'TN',\n",
       " 'website': 'http://www.alexander.senate.gov/'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senator_dict = [{i.name:i.text for i in list(member.children) if i != '\\n'} for member in list(senate_soup.find_all('member'))]\n",
    "senator_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we parse out the building, room, and ZIP code from the Senate office fields? We could use regular expressions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'455 Dirksen Senate Office Building Washington DC 20510'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_address = senator_dict[0]['address']\n",
    "example_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of really advanced and specialized terminology around writing regular expressions. The [documentation](https://docs.python.org/3/library/re.html) can be arcane to read, but there are some basic symbols we can play with.\n",
    "\n",
    "| Symbol | Function |\n",
    "| --- | --- | \n",
    "| \\b | Word boundary (zero width) |\n",
    "| \\d | Any decimal digit (equivalent to [0-9]) |\n",
    "| \\D | Any non-digit character (equivalent to [^0-9]) |\n",
    "| \\s | Any whitespace character (equivalent to [ \\t\\n\\r\\f\\v]) |\n",
    "| \\S | Any non-whitespace character (equivalent to [^ \\t\\n\\r\\f\\v]) |\n",
    "| \\w | Any alphanumeric character (equivalent to [a-zA-Z0-9\\_]) |\n",
    "| \\W | Any non-alphanumeric character (equivalent to [^a-zA-Z0-9\\_]) |\n",
    "| \\t | The tab character |\n",
    "| \\n | The newline character |\n",
    "\n",
    "Using the `\\d+` expression, we can get all the repeated digits in the string. This captures both the office number and the ZIP code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['455', '20510']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d+',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to capture exactly three digits with the `\\d{3}` expression, but this still captures part of the zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['455', '205']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{3}',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use word boundaries `\\b` in the expression to capture where words end, but this captures the last three digits of the ZIP code now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['455', '510']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{3}\\b',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use word boundaries at the beginning and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['455']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\b\\d{3}\\b',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for the ZIP code now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20510']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\b\\d{5}\\b',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can match more complex strings too. the `\\w+` syntax will match any unicode word character and combined with the \"Senate Office Building will get us the full office building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dirksen Senate Office Building']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\b\\w+\\b Senate Office Building',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parentheses will match whatever is inside. So we can match the whole string but only return the name of the office building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dirksen']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(\\b\\w+\\b) Senate Office Building',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to just matching all the words with a word end or beginning picks up all the phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['455', 'Dirksen', 'Senate', 'Office', 'Building', 'Washington', 'DC', '20510']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(\\b\\w+\\b)',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend there wasn't a \"party\" field but the only party information we had was inside the \"member_full\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexander (R-TN)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_member_full = senator_dict[0]['member_full']\n",
    "example_member_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can match any character with the `.` dot and catch all of them with the `+`. However, we want the content inside the parentheses but we know from above that the parentheses inside a regex have special functions. So we can *escape* the parentheses with a forward slash so that the pattern actually tries to match parentheses in the string itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(R-TN)'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\(.+\\)',example_member_full)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(R-TN)'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\(R-TN\\)',example_member_full)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(R-TN)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\(\\w-\\w{2}\\)',example_member_full)[0] # Now matches R and any \"-XX\" where x are any word characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again assuming that every senator is a Democrat, Republican, or Independent, we can also try to match combinations of regular expressions. For instance, we can match the D, R, or I joined by the pipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\(D|R|I-\\w{2}\\)',example_member_full)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine we wanted to catch the state instead. The pipe notation we used above is \"greedy\" in the sense that once they match, it stops looking so we never get to return the state abbreviate we indended it should return inside the parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\(D|R|I-(\\w{2})\\)',example_member_full)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution is to put the `D|R|I` inside parentheses so that both matches are treated equally and will return even if they're for different purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('R', 'TN')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\((D|R|I)-(\\w{2})\\)',example_member_full)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back up a step and swap out the `D|R|I` and just match any one-character party identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TN'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\(\\w-(\\w{2})\\)',example_member_full)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine all of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamar Alexander (R) represents TN: Office room is 455, building is Dirksen, and ZIP is 20510\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-645e903caa5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moffice_room\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b\\d{3}\\b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msenator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moffice_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b\\d{5}\\b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msenator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moffice_building\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(\\b\\w+\\b) Senate Office Building'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msenator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mparty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\((R|D|I)-\\w{2}\\)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msenator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'member_full'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\(\\w-(\\w{2})\\)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexample_member_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for senator in senator_dict:\n",
    "    office_room = re.findall(r'\\b\\d{3}\\b',senator['address'])[0]\n",
    "    office_zip = re.findall(r'\\b\\d{5}\\b',senator['address'])[0]\n",
    "    office_building = re.findall(r'(\\b\\w+\\b) Senate Office Building',senator['address'])[0]\n",
    "    party = re.findall(r'\\((R|D|I)-\\w{2}\\)',senator['member_full'])[0]\n",
    "    state = re.findall(r'\\(\\w-(\\w{2})\\)',example_member_full)[0]\n",
    "    print('{0} {1} ({2}) represents {3}: Office room is {4}, building is {5}, and ZIP is {6}'.format(senator['first_name'],senator['last_name'],party,state,office_room,office_building,office_zip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out Tammy Baldwin doesn't have a \"Senate Office Building\" in her address. An inconsistency in the raw data! Oh well, such is the data life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'709 Hart Washington DC 20510'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exception_address = senator_dict[1]['address']\n",
    "exception_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to code for these kinds of exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hart']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d+ (\\w+|\\w+ Senate Office Building).+Washington',exception_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure it still matches the initial `example_address` test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dirksen']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d+ (\\w+|\\w+ Senate Office Building).+Washington',example_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should skip her for now then. It looks like there are still a few more inconsistencies in the data, but we're still getting most of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamar Alexander (R) represents TN: Office room is 455, building is Dirksen, and ZIP is 20510\n",
      "Tammy Baldwin (D) represents WI: Office room is 709, building is Hart, and ZIP is 20510\n",
      "John Barrasso (R) represents WY: Office room is 307, building is Dirksen, and ZIP is 20510\n",
      "Michael F. Bennet (D) represents CO: Office room is 261, building is Russell, and ZIP is 20510\n",
      "Richard Blumenthal (D) represents CT: Office room is 706, building is Hart, and ZIP is 20510\n",
      "Roy Blunt (R) represents MO: Office room is 260, building is Russell, and ZIP is 20510\n",
      "Cory A. Booker (D) represents NJ: Office room is 359, building is Dirksen, and ZIP is 20510\n",
      "John Boozman (R) represents AR: Office room is 141, building is Hart, and ZIP is 20510\n",
      "Sherrod Brown (D) represents OH: Office room is 713, building is Hart, and ZIP is 20510\n",
      "Richard Burr (R) represents NC: Office room is 217, building is Russell, and ZIP is 20510\n",
      "Maria Cantwell (D) represents WA: Office room is 511, building is Hart, and ZIP is 20510\n",
      "Shelley Moore Capito (R) represents WV: Office room is 172, building is Russell, and ZIP is 20510\n",
      "Benjamin L. Cardin (D) represents MD: Office room is 509, building is Hart, and ZIP is 20510\n",
      "Thomas R. Carper (D) represents DE: Office room is 513, building is Hart, and ZIP is 20510\n",
      "Robert P., Jr. Casey (D) represents PA: Office room is 393, building is Russell, and ZIP is 20510\n",
      "Bill Cassidy (R) represents LA: Office room is 520, building is Hart, and ZIP is 20510\n",
      "Thad Cochran (R) represents MS: Office room is 113, building is Dirksen, and ZIP is 20510\n",
      "Susan M. Collins (R) represents ME: Office room is 413, building is Dirksen, and ZIP is 20510\n",
      "Christopher A. Coons had an error\n",
      "Bob Corker (R) represents TN: Office room is 425, building is Dirksen, and ZIP is 20510\n",
      "John Cornyn (R) represents TX: Office room is 517, building is Hart, and ZIP is 20510\n",
      "Catherine Cortez Masto had an error\n",
      "Tom Cotton (R) represents AR: Office room is 124, building is Russell, and ZIP is 20510\n",
      "Mike Crapo (R) represents ID: Office room is 239, building is Dirksen, and ZIP is 20510\n",
      "Ted Cruz (R) represents TX: Office room is 404, building is Russell, and ZIP is 20510\n",
      "Steve Daines (R) represents MT: Office room is 320, building is Hart, and ZIP is 20510\n",
      "Joe Donnelly (D) represents IN: Office room is 720, building is Hart, and ZIP is 20510\n",
      "Tammy Duckworth (D) represents IL: Office room is 524, building is Hart, and ZIP is 20510\n",
      "Richard J. Durbin (D) represents IL: Office room is 711, building is Hart, and ZIP is 20510\n",
      "Michael B. Enzi had an error\n",
      "Joni Ernst (R) represents IA: Office room is 111, building is Russell, and ZIP is 20510\n",
      "Dianne Feinstein (D) represents CA: Office room is 331, building is Hart, and ZIP is 20510\n",
      "Deb Fischer (R) represents NE: Office room is 454, building is Russell, and ZIP is 20510\n",
      "Jeff Flake (R) represents AZ: Office room is 413, building is Russell, and ZIP is 20510\n",
      "Al Franken (D) represents MN: Office room is 309, building is Hart, and ZIP is 20510\n",
      "Cory Gardner (R) represents CO: Office room is 354, building is Russell, and ZIP is 20510\n",
      "Kirsten E. Gillibrand (D) represents NY: Office room is 478, building is Russell, and ZIP is 20510\n",
      "Lindsey Graham (R) represents SC: Office room is 290, building is Russell, and ZIP is 20510\n",
      "Chuck Grassley (R) represents IA: Office room is 135, building is Hart, and ZIP is 20510\n",
      "Kamala D. Harris (D) represents CA: Office room is 112, building is Hart, and ZIP is 20510\n",
      "Margaret Wood Hassan (D) represents NH: Office room is 330, building is Hart, and ZIP is 20510\n",
      "Orrin G. Hatch (R) represents UT: Office room is 104, building is Hart, and ZIP is 20510\n",
      "Martin Heinrich (D) represents NM: Office room is 303, building is Hart, and ZIP is 20510\n",
      "Heidi Heitkamp (D) represents ND: Office room is 516, building is Hart, and ZIP is 20510\n",
      "Dean Heller (R) represents NV: Office room is 324, building is Hart, and ZIP is 20510\n",
      "Mazie K. Hirono (D) represents HI: Office room is 730, building is Hart, and ZIP is 20510\n",
      "John Hoeven (R) represents ND: Office room is 338, building is Russell, and ZIP is 20510\n",
      "James M. Inhofe (R) represents OK: Office room is 205, building is Russell, and ZIP is 20510\n",
      "Johnny Isakson (R) represents GA: Office room is 131, building is Russell, and ZIP is 20510\n",
      "Ron Johnson (R) represents WI: Office room is 328, building is Hart, and ZIP is 20510\n",
      "Tim Kaine (D) represents VA: Office room is 231, building is Russell, and ZIP is 20510\n",
      "John Kennedy (R) represents LA: Office room is B11, building is Russell, and ZIP is 20510\n",
      "Angus S., Jr. King (I) represents ME: Office room is 133, building is Hart, and ZIP is 20510\n",
      "Amy Klobuchar (D) represents MN: Office room is 302, building is Hart, and ZIP is 20510\n",
      "James Lankford (R) represents OK: Office room is 316, building is Hart, and ZIP is 20510\n",
      "Patrick J. Leahy (D) represents VT: Office room is 437, building is Russell, and ZIP is 20510\n",
      "Mike Lee had an error\n",
      "Joe, III Manchin (D) represents WV: Office room is 306, building is Hart, and ZIP is 20510\n",
      "Edward J. Markey (D) represents MA: Office room is 255, building is Dirksen, and ZIP is 20510\n",
      "John McCain (R) represents AZ: Office room is 218, building is Russell, and ZIP is 20510\n",
      "Claire McCaskill (D) represents MO: Office room is 503, building is Hart, and ZIP is 20510\n",
      "Mitch McConnell (R) represents KY: Office room is 317, building is Russell, and ZIP is 20510\n",
      "Robert Menendez (D) represents NJ: Office room is 528, building is Hart, and ZIP is 20510\n",
      "Jeff Merkley (D) represents OR: Office room is 313, building is Hart, and ZIP is 20510\n",
      "Jerry Moran (R) represents KS: Office room is 521, building is Dirksen, and ZIP is 20510\n",
      "Lisa Murkowski (R) represents AK: Office room is 522, building is Hart, and ZIP is 20510\n",
      "Christopher Murphy (D) represents CT: Office room is 136, building is Hart, and ZIP is 20510\n",
      "Patty Murray (D) represents WA: Office room is 154, building is Russell, and ZIP is 20510\n",
      "Bill Nelson (D) represents FL: Office room is 716, building is Hart, and ZIP is 20510\n",
      "Rand Paul (R) represents KY: Office room is 167, building is Russell, and ZIP is 20510\n",
      "David Perdue (R) represents GA: Office room is 383, building is Russell, and ZIP is 20510\n",
      "Gary C. Peters (D) represents MI: Office room is 724, building is Hart, and ZIP is 20510\n",
      "Rob Portman (R) represents OH: Office room is 448, building is Russell, and ZIP is 20510\n",
      "Jack Reed (D) represents RI: Office room is 728, building is Hart, and ZIP is 20510\n",
      "James E. Risch (R) represents ID: Office room is 483, building is Russell, and ZIP is 20510\n",
      "Pat Roberts (R) represents KS: Office room is 109, building is Hart, and ZIP is 20510\n",
      "Mike Rounds (R) represents SD: Office room is 502, building is Hart, and ZIP is 20510\n",
      "Marco Rubio (R) represents FL: Office room is 284, building is Russell, and ZIP is 20510\n",
      "Bernard Sanders (I) represents VT: Office room is 332, building is Dirksen, and ZIP is 20510\n",
      "Ben Sasse (R) represents NE: Office room is 136, building is Russell, and ZIP is 20510\n",
      "Brian Schatz (D) represents HI: Office room is 722, building is Hart, and ZIP is 20510\n",
      "Charles E. Schumer (D) represents NY: Office room is 322, building is Hart, and ZIP is 20510\n",
      "Tim Scott (R) represents SC: Office room is 717, building is Hart, and ZIP is 20510\n",
      "Jeanne Shaheen (D) represents NH: Office room is 506, building is Hart, and ZIP is 20510\n",
      "Richard C. Shelby (R) represents AL: Office room is 304, building is Russell, and ZIP is 20510\n",
      "Debbie Stabenow (D) represents MI: Office room is 731, building is Hart, and ZIP is 20510\n",
      "Luther Strange had an error\n",
      "Dan Sullivan (R) represents AK: Office room is 702, building is Hart, and ZIP is 20510\n",
      "Jon Tester (D) represents MT: Office room is 311, building is Hart, and ZIP is 20510\n",
      "John Thune (R) represents SD: Office room is 511, building is Dirksen, and ZIP is 20510\n",
      "Thom Tillis (R) represents NC: Office room is 185, building is Dirksen, and ZIP is 20510\n",
      "Patrick J. Toomey (R) represents PA: Office room is 248, building is Russell, and ZIP is 20510\n",
      "Tom Udall (D) represents NM: Office room is 531, building is Hart, and ZIP is 20510\n",
      "Chris Van Hollen (D) represents MD: Office room is 110, building is Hart, and ZIP is 20510\n",
      "Mark R. Warner (D) represents VA: Office room is 703, building is Hart, and ZIP is 20510\n",
      "Elizabeth Warren (D) represents MA: Office room is 317, building is Hart, and ZIP is 20510\n",
      "Sheldon Whitehouse (D) represents RI: Office room is 530, building is Hart, and ZIP is 20510\n",
      "Roger F. Wicker (R) represents MS: Office room is 555, building is Dirksen, and ZIP is 20510\n",
      "Ron Wyden (D) represents OR: Office room is 221, building is Dirksen, and ZIP is 20510\n",
      "Todd Young (R) represents IN: Office room is 400, building is Russell, and ZIP is 20510\n"
     ]
    }
   ],
   "source": [
    "for senator in senator_dict:\n",
    "    try:\n",
    "        office_room = re.findall(r'\\b\\w{3,4}\\b',senator['address'])[0]\n",
    "        office_zip = re.findall(r'\\b\\d{5}\\b',senator['address'])[0]\n",
    "        office_building = re.findall(r'\\d+ (\\w+|\\w+ Senate Office Building).+Washington',senator['address'])[0]\n",
    "        party = re.findall(r'\\((R|D|I)-\\w{2}\\)',senator['member_full'])[0]\n",
    "        state = re.findall(r'\\(\\w-(\\w{2})\\)',senator['member_full'])[0]\n",
    "        print('{0} {1} ({2}) represents {3}: Office room is {4}, building is {5}, and ZIP is {6}'.format(senator['first_name'],senator['last_name'],party,state,office_room,office_building,office_zip))\n",
    "    except IndexError:\n",
    "        print('{0} {1} had an error'.format(senator['first_name'],senator['last_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
