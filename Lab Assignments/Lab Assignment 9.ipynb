{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 9 - Not Sorting, but Networks\n",
    "\n",
    "We're not doing sorting anymore, but we're going to skip ahead to next week's content on graphs and networks. But we'll mix it up a bit with some web-scraping as well.\n",
    "\n",
    "Import all the stuff we might need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sb\n",
    "import requests\n",
    "import networkx as nx\n",
    "from bs4 import BeautifulSoup, NavigableString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tournament page data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = requests.get('http://www.sports-reference.com/cbb/postseason/2017-ncaa.html').text\n",
    "soup = BeautifulSoup(raw,'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse out all the divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "east_soup = soup.find_all('div',{'id':'east'})\n",
    "midwest_soup = soup.find_all('div',{'id':'midwest'})\n",
    "south_soup = soup.find_all('div',{'id':'south'})\n",
    "west_soup = soup.find_all('div',{'id':'west'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to get all the teams in each division by parsing the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cbb/schools/southern-methodist/2017.html'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_soup[0].find_all('a')[8]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cbb/schools/villanova/2017.html',\n",
       " '/cbb/schools/mount-st-marys/2017.html',\n",
       " '/cbb/schools/wisconsin/2017.html',\n",
       " '/cbb/schools/virginia-tech/2017.html',\n",
       " '/cbb/schools/virginia/2017.html',\n",
       " '/cbb/schools/north-carolina-wilmington/2017.html',\n",
       " '/cbb/schools/florida/2017.html',\n",
       " '/cbb/schools/east-tennessee-state/2017.html',\n",
       " '/cbb/schools/southern-methodist/2017.html',\n",
       " '/cbb/schools/baylor/2017.html',\n",
       " '/cbb/schools/new-mexico-state/2017.html',\n",
       " '/cbb/schools/south-carolina/2017.html',\n",
       " '/cbb/schools/marquette/2017.html',\n",
       " '/cbb/schools/duke/2017.html',\n",
       " '/cbb/schools/troy/2017.html']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_teams(division_soup):\n",
    "    teams_href_list = list()\n",
    "    for link in division_soup[0].find_all('a'):\n",
    "        if len(link.text) > 0:\n",
    "            teams_href_list.append(link['href'])\n",
    "\n",
    "    return teams_href_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function on each division's `soup` and add them all together for a list of all teams in the 2017 tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_teams_2017 = get_teams(east_soup)\n",
    "midwest_teams_2017 = get_teams(midwest_soup)\n",
    "south_teams_2017 = get_teams(south_soup)\n",
    "west_teams_2017 = get_teams(west_soup)\n",
    "teams_2017 = east_teams_2017 + midwest_teams_2017 + south_teams_2017 + west_teams_2017\n",
    "len(teams_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a `tournament_teams` by looping through `teams_2017` and for each element applying the `.text` attribute to extract the cleaned name of the team and append it to `tournament_teams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tournament_teams = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the `href` out of a single team in `teams_2017`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cbb/schools/villanova/2017.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_2017[0]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually want the \"2017-schedule.html\" not \"2017.html\" Use the `replace` string function to update the `href`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.sports-reference.com/cbb/schools/villanova/2017-schedule.html'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'http://www.sports-reference.com' + teams_2017[0].replace('2017','2017-schedule')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawl the data for a single team:\n",
    "\n",
    "1. Make a `_url` variable that combines the domain (\"http://www.sports-reference.com/\") and the `href` updated to contain \"2017-schedule.html\".\n",
    "2. Use requests' `get` and `text` methods to get the raw HTML, saving it as `team_raw`\n",
    "3. Make `team_soup` out of `team_raw`\n",
    "4. Find the specific table containing the schedule and save it as `schedule_table`.\n",
    "\n",
    "**HINT**: The table has both a \"class\" and an \"id\", both of which you can pass to the `.find_all()` method inside a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"left \" csk=\"2016-12-10\" data-stat=\"date_game\"><a href=\"/cbb/boxscores/2016-12-10-notre-dame.html\">Sat, Dec 10, 2016</a></td>,\n",
       " <td class=\"left \" data-stat=\"time_game\">12:00 pm/est</td>,\n",
       " <td class=\"left \" data-stat=\"network\"></td>,\n",
       " <td class=\"left \" data-stat=\"game_type\">REG</td>,\n",
       " <td class=\"left \" data-stat=\"game_location\">N</td>,\n",
       " <td class=\"left \" data-stat=\"opp_name\"><a href=\"/cbb/schools/notre-dame/2017.html\">Notre Dame</a>Â <span class=\"note\">(23)</span></td>,\n",
       " <td class=\"left \" data-stat=\"conf_abbr\"><a href=\"/cbb/conferences/acc/2017.html\" title=\"Atlantic Coast Conference\">ACC</a></td>,\n",
       " <td class=\"left \" data-stat=\"game_result\">W</td>,\n",
       " <td class=\"right \" data-stat=\"pts\">74</td>,\n",
       " <td class=\"right \" data-stat=\"opp_pts\">66</td>,\n",
       " <td class=\"center \" data-stat=\"overtimes\"></td>,\n",
       " <td class=\"right \" data-stat=\"wins\">10</td>,\n",
       " <td class=\"right \" data-stat=\"losses\">0</td>,\n",
       " <td class=\"left \" csk=\"10\" data-stat=\"game_streak\">W 10</td>,\n",
       " <td class=\"left \" data-stat=\"arena\">Prudential Center</td>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = requests.get('http://www.sports-reference.com/cbb/schools/villanova/2017-schedule.html').text\n",
    "soup = BeautifulSoup(raw,'lxml')\n",
    "\n",
    "schedule_table = soup.find_all('table',{'id':'schedule','class':\"sortable stats_table\"})\n",
    "row = schedule_table[0].find_all('tr')[10]\n",
    "row.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_table[0].find_all('td',{'data-stat':'opp_pts'})[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Parse the `schedule_table`\n",
    "\n",
    "Using the `schedule_table` soup object, parse out all of the relevant cells.\n",
    "\n",
    "First, parse out the dates and save this list of values as `dates`. Your best bet is to take advantage of the \"data-stat\" tag identifer for each of the steps below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, parse out the opponents and save this list of values as `opponents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, parse out the results and save this list of values as `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth, parse out the team score and save this list of values as `team_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifth, parse out the opponent's score as save this list of values as `opp_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the final step, a brief aside on how Python's zip function works. Consider three lists below, the `zip` function will combine them all for you. Note that `zip` returns an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x13c6ab40988>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = ['a','b','c']\n",
    "list2 = [0,1,2]\n",
    "list3 = ['alpha','beta','gamma']\n",
    "\n",
    "zip(list1,list2,list3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we wrap the `zip` inside a `list` to make it spill its guts. We see that the first element of `list1`, the first element of `list2`, and the first element of `list3` were combined together into a tuple and this tuple is the first element in a list. Then the second elements of the lists became a tuple in the second elemnt of the list, *etc*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0, 'alpha'), ('b', 1, 'beta'), ('c', 2, 'gamma')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list1,list2,list3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, combine all five of the lists of values you extracted above together using Python's `zip` function and save the list of results as `team_results`. Show your team results by calling `team_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Crawl all of the teams' tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a loop that goes through each team in `teams_2017` and does all of the steps above in each pass.\n",
    "\n",
    "0. Before the loop starts, has an empty list `all_results`\n",
    "1. Checks to make sure the `team.text` isn't empty, skips urls that point to \"tbd\", or handles index position errors from pages with empty tables.\n",
    "2. Takes the team object the url with the `href` replacement\n",
    "3. Uses requests' `get` and `text` methods to get the raw HTML\n",
    "4. Turns the raw HTML into Soup\n",
    "5. Finds the table\n",
    "6. Finds the dates, opponents, results, team score, and opponent scores\n",
    "7. Zips them all together into `team_results`\n",
    "8. For each result in `team_results` appends it to `all_results`\n",
    "\n",
    "There's 64 team pages to visit, so if it takes ~0.5 seconds to download and parse each one, this might take about 30 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_results = list()\n",
    "for team in teams_2017:\n",
    "    if len(team.text) > 0:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over `all_results` and only keep results for winners to avoid double-counting by adding them to a new `reduced_results` list. You can identify winners either by the result tag or by comparing the score and opp_score values.\n",
    "\n",
    "Print out the length of the `all_results` and `reduced_results` to confirm that you really got rid of the games. How many games remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2060, 1455)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_results = list()\n",
    "\n",
    "        \n",
    "len(all_results), len(reduced_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reduce the results again to only include the matches between teams that started out in the 1st round of the tournament. Loop through `reduced_results`, check if the opponent is in `tournament_teams` (defined in Problem 1), and add the result to `tournament_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Villanova', 'Purdue', '2016-11-14', '79', '76'),\n",
       " ('Villanova', 'Notre Dame', '2016-12-10', '74', '66'),\n",
       " ('Villanova', 'Creighton', '2016-12-31', '80', '70'),\n",
       " ('Villanova', 'Marquette', '2017-01-07', '93', '81'),\n",
       " ('Villanova', 'Xavier', '2017-01-10', '79', '54'),\n",
       " ('Villanova', 'Seton Hall', '2017-01-16', '76', '46'),\n",
       " ('Villanova', 'Virginia', '2017-01-29', '61', '59'),\n",
       " ('Villanova', 'Xavier', '2017-02-11', '73', '57'),\n",
       " ('Villanova', 'Seton Hall', '2017-02-18', '92', '70'),\n",
       " ('Villanova', 'Creighton', '2017-02-25', '79', '63')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tournament_results = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, your `tournament_results` should look something like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[('Northwestern', 'Dayton', '2016-12-17', 'W', '67', '64'),\n",
    " ('Northwestern', 'Wisconsin', '2017-02-12', 'W', '66', '59'),\n",
    " ('Northwestern', 'Michigan', '2017-03-01', 'W', '67', '65'),\n",
    " ('Northwestern', 'Maryland', '2017-03-10', 'W', '72', '64')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do in class: Make a directed graph\n",
    "\n",
    "If team *i* beat team *j* by *w* points, create an edge from node *i* towards node *j* with weight *w*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative point differential for: Creighton-Marquette\n",
      "\n",
      "Negative point differential for: Michigan-UCLA\n",
      "\n",
      "Negative point differential for: Texas Southern-Louisville\n",
      "\n",
      "Negative point differential for: Winthrop-Florida State\n",
      "\n",
      "There are 58 nodes and 222 edges in the network\n"
     ]
    }
   ],
   "source": [
    "g = nx.DiGraph()\n",
    "\n",
    "for (team, opponent, date, score, opp_score) in tournament_results:\n",
    "    differential = int(score) - int(opp_score)\n",
    "    if differential > 0:\n",
    "        if g.has_edge(team,opponent):\n",
    "            g[team][opponent]['weight'] += differential\n",
    "        else:\n",
    "            g.add_edge(team, opponent, weight = abs(differential))\n",
    "    else:\n",
    "        print('Negative point differential for: {0}-{1}\\n'.format(team,opponent))\n",
    "        if g.has_edge(team,opponent):\n",
    "            g[team][opponent]['weight'] += differential\n",
    "        else:\n",
    "            g.add_edge(team, opponent, weight = abs(differential))\n",
    "        \n",
    "print(\"There are {0} nodes and {1} edges in the network\".format(g.number_of_nodes(), g.number_of_edges()))\n",
    "\n",
    "nx.write_gexf(g,'tournament_schedule.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
